{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd41deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FixB(12ì‹œ=0Â°, CCW) â†’ 12ì‹œ=0Â°, CW ì˜ 180Â° ë°˜ì „(FixB_180) íŒŒì´í”„ë¼ì¸\n",
    "# - raw CSV ë³´ì¡´ â†’ ë¯¸ë¦¬ë³´ê¸°(as_is/fixB/fixB_180, ë™ì¼ ìƒ˜í”Œ) â†’ fixed CSV ìƒì„± â†’ í•™ìŠµ\n",
    "# - ResNet-18 êµ¬ì¡°ë¥¼ ì§ì ‘ ë ˆì´ì–´ ì„¤ì •í•˜ì—¬ í†µí•© (ë””ë²„ê¹… ìš©ì´ì„±)\n",
    "# ============================================================\n",
    "import os, math, csv, glob, random, cv2, numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # ResNet-18 ì§ì ‘ êµ¬í˜„ì„ ìœ„í•´ ì¶”ê°€\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "# torchvision.modelsëŠ” ì§ì ‘ êµ¬í˜„í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì œê±°\n",
    "# import torchvision.models as tvm \n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------\n",
    "# ğŸ“Œ ResNet-18 ì§ì ‘ êµ¬í˜„ ë ˆì´ì–´ ì •ì˜ (ì§ì ‘ë ˆì´ì–´ì†ŒìŠ¤ì½”ë“œ ë‚´ìš©)\n",
    "# ------------------------------------\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution for downsampling\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18ì˜ ê¸°ë³¸ ë¸”ë¡ (BasicBlock) êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # 1. Conv1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 2. Conv2\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        # Downsample ê²½ë¡œ\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # ì”ì°¨ ì—°ê²°ì„ ìœ„í•œ ì…ë ¥ ê°’ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Downsample ê²½ë¡œê°€ ìˆë‹¤ë©´ ì‹¤í–‰ (ì°¨ì› ë§ì¶”ê¸°)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # ì”ì°¨ ì—°ê²° (Residual Connection)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18 êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        # 1. ì´ˆê¸° Convolution, BN, ReLU, MaxPool\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 2. ResNet ìŠ¤í…Œì´ì§€ (layer1 ~ layer4)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0]) \n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # 3. ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´: num_classes=2 (sin, cos)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # ResNet-18ì˜ ìµœì¢… ì¶œë ¥ ì±„ë„ì€ 512 * BasicBlock.expansion = 512ì…ë‹ˆë‹¤.\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes) \n",
    "\n",
    "        # Weight Initialization (he_normalê³¼ ìœ ì‚¬í•œ Kaiming Initialization)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. ì´ˆê¸° ë ˆì´ì–´\n",
    "        x = self.conv1(x)\n",
    "        # ğŸ“Œ ë””ë²„ê¹… í¬ì¸íŠ¸: conv1 ì¶œë ¥ í¬ê¸° í™•ì¸\n",
    "        # print(\"After conv1:\", x.shape) \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        # ğŸ“Œ ë””ë²„ê¹… í¬ì¸íŠ¸: maxpool ì¶œë ¥ í¬ê¸° í™•ì¸\n",
    "        # print(\"After maxpool:\", x.shape) \n",
    "\n",
    "        # 2. ìŠ¤í…Œì´ì§€\n",
    "        x = self.layer1(x)\n",
    "        # print(\"After layer1:\", x.shape)\n",
    "        x = self.layer2(x)\n",
    "        # print(\"After layer2:\", x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(\"After layer3:\", x.shape)\n",
    "        x = self.layer4(x)\n",
    "        # print(\"After layer4:\", x.shape)\n",
    "\n",
    "        # 3. ìµœì¢… ë¶„ë¥˜\n",
    "        x = self.avgpool(x)\n",
    "        # print(\"After avgpool:\", x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(\"After flatten:\", x.shape)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18_custom(num_classes=2):\n",
    "    \"\"\"\n",
    "    ì§ì ‘ êµ¬í˜„í•œ ResNet-18 (BasicBlock, [2, 2, 2, 2] ë¸”ë¡ êµ¬ì„±)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ResNet-18ì€ [2, 2, 2, 2] ë¸”ë¡ êµ¬ì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# ------------------------------------\n",
    "# ğŸ“Œ ìˆ˜ì •í•  ì†ŒìŠ¤ì½”ë“œ\n",
    "# ------------------------------------\n",
    "# (ìƒëµëœ ìƒìœ„ import, ê²½ë¡œ ì„¤ì •, CSV ì •ë¦¬/ë³€í™˜ í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "# ...\n",
    "# -----------------\n",
    "# Dataset / Model\n",
    "# -----------------\n",
    "class DialDataset(Dataset):\n",
    "# (DialDataset í´ë˜ìŠ¤ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "# ...\n",
    "    def __init__(self, csv_path, img_size=224, augment=True):\n",
    "        self.items=[]\n",
    "        with open(csv_path,\"r\",encoding=\"utf-8\") as f:\n",
    "            r=csv.reader(f); next(r)\n",
    "            for fp, th, s, c in r:\n",
    "                if os.path.isfile(fp):\n",
    "                    self.items.append((fp,float(th),float(s),float(c)))\n",
    "        if not self.items:\n",
    "            raise RuntimeError(f\"ìœ íš¨ í•­ëª© 0: {csv_path}\")\n",
    "        augs=[]\n",
    "        if augment: augs += [T.ColorJitter(brightness=0.2, contrast=0.2)]\n",
    "        self.tfm=T.Compose(augs+[\n",
    "            T.Resize((img_size,img_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Lambda(lambda x: x.expand(3,-1,-1)),\n",
    "            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "        ])\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self,i):\n",
    "        fp, th, s, c=self.items[i]\n",
    "        # x=self.tfm(Image.open(fp).convert(\"L\"))\n",
    "        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë¡œë“œ í›„ 3ì±„ë„ë¡œ í™•ì¥í•˜ëŠ” ë¡œì§ì´ T.Lambdaì— ìˆìŒ\n",
    "        x=self.tfm(Image.open(fp).convert(\"L\"))\n",
    "        y=torch.tensor([s,c],dtype=torch.float32)\n",
    "        return x,y\n",
    "\n",
    "\n",
    "class AngleHead(nn.Module): \n",
    "    \"\"\"\n",
    "    ì§ì ‘ êµ¬í˜„í•œ ResNet-18ì„ Backboneìœ¼ë¡œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2): # num_classes ì¸ì ì¶”ê°€ (ê¸°ì¡´ ResNet í´ë˜ìŠ¤ì— ë§ì¶”ê¸° ìœ„í•´)\n",
    "        super().__init__()\n",
    "        # ğŸ“Œ ìˆ˜ì • ì‚¬í•­: torchvision.models.resnet18 ëŒ€ì‹  ì§ì ‘ êµ¬í˜„í•œ resnet18_custom ì‚¬ìš©\n",
    "        self.backbone = resnet18_custom(num_classes=num_classes) \n",
    "        \n",
    "        # Note: resnet18_custom ë‚´ë¶€ì—ì„œ ì´ë¯¸ self.fc = nn.Linear(512, num_classes)ë¡œ \n",
    "        # ìµœì¢… ë ˆì´ì–´ê°€ ì„¤ì •ë˜ì—ˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ fc ë ˆì´ì–´ë¥¼ êµì²´í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "        # ê¸°ì¡´: self.backbone = tvm.resnet18(weights=None)\n",
    "        # ê¸°ì¡´: self.backbone.fc = nn.Linear(self.backbone.fc.in_features, 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=self.backbone(x)\n",
    "        # ğŸ“Œ ì¤‘ìš”: ê¸°ì¡´ ì½”ë“œì˜ ì¶œë ¥ ì •ê·œí™” ë¡œì§ ìœ ì§€\n",
    "        return y/(y.norm(dim=1,keepdim=True)+1e-8)\n",
    "\n",
    "def angle_mae_deg(p,t):\n",
    "    dot=(p*t).sum(dim=1).clamp(-1,1)\n",
    "    ang=torch.acos(dot)*180.0/math.pi\n",
    "    return ang.mean().item()\n",
    "\n",
    "# -----------------\n",
    "# í•™ìŠµ (FIXED CSV ì‚¬ìš©) - MSE ì¶”ì  ì¶”ê°€\n",
    "# -----------------\n",
    "def train_r18(csv_tr=CSV_TRAIN_FIXED, csv_va=CSV_TEST_FIXED,\n",
    "              img_size=224, epochs=30, batch=32, lr=3e-4):\n",
    "    global timestamp\n",
    "    # ... (ìƒëµëœ í•™ìŠµ ì½”ë“œ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ds_tr=DialDataset(csv_tr, img_size, augment=True)\n",
    "    try:\n",
    "        ds_va=DialDataset(csv_va, img_size, augment=False)\n",
    "    except:\n",
    "        print(\"âš ï¸ val CSV ì—†ìŒ â†’ train 15%ë¥¼ valë¡œ ì‚¬ìš©\")\n",
    "        n=len(ds_tr); k=max(1,int(n*0.15))\n",
    "        ds_va=torch.utils.data.Subset(ds_tr, list(range(k)))\n",
    "        ds_tr=torch.utils.data.Subset(ds_tr, list(range(k,n)))\n",
    "\n",
    "    dl_tr=DataLoader(ds_tr, batch_size=batch, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dl_va=DataLoader(ds_va, batch_size=batch, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    LOG_DIR = os.path.join(ROOT, \"runs\", f\"r18_fixb180_{timestamp}\")\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "    print(f\"ğŸ“Š TensorBoard ë¡œê·¸ ë””ë ‰í† ë¦¬: {LOG_DIR}\")\n",
    "\n",
    "    # ğŸ“Œ AngleHead ìƒì„± ì‹œ num_classes=2 ëª…ì‹œ (ê¸°ë³¸ê°’)\n",
    "    model=AngleHead(num_classes=2).to(device) \n",
    "    \n",
    "    # ğŸ“Œ ë””ë²„ê¹… í¬ì¸íŠ¸: ëª¨ë¸ êµ¬ì¡° í™•ì¸ (ì§ì ‘ êµ¬í˜„í•œ ResNet ë ˆì´ì–´ í™•ì¸)\n",
    "    print(\"\\n--- Custom ResNet-18 (AngleHead) Model Structure ---\")\n",
    "    print(model)\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "    \n",
    "    # ğŸ“Œ ë””ë²„ê¹… í¬ì¸íŠ¸: ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ í•œ ë²ˆ í†µê³¼ì‹œì¼œ ê° ë ˆì´ì–´ í¬ê¸° í™•ì¸\n",
    "    try:\n",
    "        dummy_input = torch.randn(batch, 3, img_size, img_size).to(device)\n",
    "        dummy_output = model(dummy_input)\n",
    "        print(f\"âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ í†µê³¼: ì…ë ¥ {dummy_input.shape} â†’ ì¶œë ¥ {dummy_output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        # ì—¬ê¸°ì— BasicBlockì´ë‚˜ ResNet.forward() ë‚´ë¶€ì— print(x.shape)ë¥¼ ë„£ì–´ ë””ë²„ê¹… ê°€ëŠ¥\n",
    "\n",
    "    opt=torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    # # ê¸°ì¡´: cos=nn.CosineEmbeddingLoss(); mse=nn.MSELoss()\n",
    "    # # ìˆ˜ì •: (reduction='mean'ìœ¼ë¡œ ëª…ì‹œ)\n",
    "    cos=nn.CosineEmbeddingLoss(reduction='mean')\n",
    "    mse=nn.MSELoss(reduction='mean')\n",
    "    sch=torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "    best=1e9\n",
    "    best_ckpt_path = \"\"\n",
    "\n",
    "    for ep in range(1,epochs+1):\n",
    "        # ... (ì´í›„ í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "        # ========== Training ==========\n",
    "        model.train()\n",
    "        tr_total = 0.0\n",
    "        tr_cos_sum = 0.0\n",
    "        tr_mse_sum = 0.0\n",
    "        \n",
    "        for x,y in dl_tr:\n",
    "            x,y=x.to(device), y.to(device)\n",
    "            p=model(x)\n",
    "            tgt=torch.ones(p.size(0), device=device)\n",
    "            \n",
    "            loss_cos = cos(p,y,tgt)\n",
    "            loss_mse = mse(p,y)\n",
    "            loss = loss_cos + 0.1*loss_mse\n",
    "            \n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            \n",
    "            tr_total += loss.item()*x.size(0)\n",
    "            tr_cos_sum += loss_cos.item()*x.size(0)\n",
    "            tr_mse_sum += loss_mse.item()*x.size(0)\n",
    "        \n",
    "        tr_total /= len(dl_tr.dataset)\n",
    "        tr_cos = tr_cos_sum / len(dl_tr.dataset)\n",
    "        tr_mse = tr_mse_sum / len(dl_tr.dataset)\n",
    "        sch.step()\n",
    "\n",
    "        # ========== Validation ==========\n",
    "        model.eval()\n",
    "        va_total = 0.0\n",
    "        va_cos_sum = 0.0\n",
    "        va_mse_sum = 0.0\n",
    "        mae = 0.0\n",
    "        n = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x,y in dl_va:\n",
    "                x,y=x.to(device), y.to(device)\n",
    "                p=model(x)\n",
    "                tgt=torch.ones(p.size(0), device=device)\n",
    "                \n",
    "                loss_cos = cos(p,y,tgt)\n",
    "                loss_mse = mse(p,y)\n",
    "                loss = loss_cos + 0.1*loss_mse\n",
    "                \n",
    "                va_total += loss.item()*x.size(0)\n",
    "                va_cos_sum += loss_cos.item()*x.size(0)\n",
    "                va_mse_sum += loss_mse.item()*x.size(0)\n",
    "                mae += angle_mae_deg(p,y)*x.size(0)\n",
    "                n += x.size(0)\n",
    "        \n",
    "        va_total /= max(1,n)\n",
    "        va_cos = va_cos_sum / max(1,n)\n",
    "        va_mse = va_mse_sum / max(1,n)\n",
    "        mae /= max(1,n)\n",
    "        \n",
    "        # ========== Console Output ==========\n",
    "        print(f\"[{ep:02d}] train {tr_total:.4f} (cos:{tr_cos:.4f}, mse:{tr_mse:.4f}) | \"\n",
    "              f\"val {va_total:.4f} (cos:{va_cos:.4f}, mse:{va_mse:.4f}) | val-MAE {mae:.2f}Â°\")\n",
    "\n",
    "        # ========== TensorBoard Logging ==========\n",
    "        writer.add_scalar('Loss/Train_Total', tr_total, ep)\n",
    "        writer.add_scalar('Loss/Train_Cosine', tr_cos, ep)\n",
    "        writer.add_scalar('Loss/Train_MSE', tr_mse, ep)\n",
    "        \n",
    "        writer.add_scalar('Loss/Validation_Total', va_total, ep)\n",
    "        writer.add_scalar('Loss/Validation_Cosine', va_cos, ep)\n",
    "        writer.add_scalar('Loss/Validation_MSE', va_mse, ep)\n",
    "        \n",
    "        writer.add_scalar('Metrics/Validation_MAE_Deg', mae, ep)\n",
    "        writer.add_scalar('Learning_Rate', opt.param_groups[0]['lr'], ep)\n",
    "\n",
    "        timestamp_save = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if mae<best:\n",
    "            best = mae\n",
    "            actual_filename = f\"notimganet_best-{timestamp_save}-mae{mae:.2f}.pth\"\n",
    "            save_path = os.path.join(CKPT_DIR, actual_filename)\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_ckpt_path = save_path\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"âœ… best val-MAE = {best:.2f}Â°  â†’ {best_ckpt_path}\")\n",
    "    return best_ckpt_path\n",
    "\n",
    "best_path = train_r18(epochs=30, batch=32, lr=3e-4)\n",
    "print(\"BEST:\", best_path)\n",
    "\n",
    "# -----------------\n",
    "# ì¶”ë¡  ì˜ˆì‹œ(ì˜¤ë²„ë ˆì´) â€“ FIXED ê¸°ì¤€\n",
    "# -----------------\n",
    "# (ì´í›„ ì¶”ë¡  ì½”ë“œëŠ” AngleHead í´ë˜ìŠ¤ê°€ ìˆ˜ì •ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)\n",
    "# ...\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# ì¶”ë¡  ì˜ˆì‹œ(ì˜¤ë²„ë ˆì´) â€“ FIXED ê¸°ì¤€\n",
    "# -----------------\n",
    "def load_for_infer(ckpt):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=AngleHead().to(device)\n",
    "    sd=torch.load(ckpt, map_location=device)\n",
    "    model.load_state_dict(sd, strict=True); model.eval()\n",
    "    tfm=T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.expand(3,-1,-1)),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    return model, tfm, device\n",
    "\n",
    "def infer_one(model, tfm, device, img_path, theta_zero_rad=0.0, ticks_per_rev=100, mm_per_rev=1.0):\n",
    "    x=tfm(Image.open(img_path).convert(\"L\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        y=model(x)[0].cpu().numpy()\n",
    "    sinp,cosp=float(y[0]), float(y[1])\n",
    "    theta=(math.atan2(sinp,cosp))%(2*math.pi)\n",
    "    delta=(theta-theta_zero_rad)%(2*math.pi)\n",
    "    ticks=delta/(2*math.pi)*ticks_per_rev\n",
    "    mm   =delta/(2*math.pi)*mm_per_rev\n",
    "    return theta, ticks, mm\n",
    "\n",
    "def save_overlay(img_path, theta_deg, value_mm, out_path):\n",
    "    g=cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h,w=g.shape[:2]; cx,cy=w//2,h//2; R=int(min(h,w)*0.45)\n",
    "    th=math.radians(theta_deg)\n",
    "    x2=int(round(cx+math.cos(th-math.pi/2)*R))\n",
    "    y2=int(round(cy+math.sin(th-math.pi/2)*R))\n",
    "    vis=cv2.cvtColor(g,cv2.COLOR_GRAY2BGR)\n",
    "    cv2.arrowedLine(vis,(cx,cy),(x2,y2),(0,255,0),2,cv2.LINE_AA,tipLength=0.06)\n",
    "    cv2.putText(vis,f\"{value_mm:.3f} mm\",(10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imwrite(out_path,vis)\n",
    "\n",
    "pngs=glob.glob(os.path.join(TEST_DIR,\"*.png\")) or glob.glob(os.path.join(TRAIN_DIR,\"*.png\"))\n",
    "if pngs:\n",
    "    model,tfm,device=load_for_infer(best_path)\n",
    "    sample=pngs[0]\n",
    "    theta_zero_deg=0.0\n",
    "    theta,ticks,mm=infer_one(model,tfm,device,sample,\n",
    "                              theta_zero_rad=math.radians(theta_zero_deg),\n",
    "                              ticks_per_rev=100, mm_per_rev=1.0)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_prev=os.path.join(DATASET_DIR,f\"_infer_notimganet_preview({timestamp}).jpg\")\n",
    "    save_overlay(sample, theta*180/math.pi, mm, out_prev)\n",
    "    print(f\"ğŸ” ì˜ˆì¸¡: Î¸={theta*180/math.pi:.2f}Â°, value={mm:.3f} mm\")\n",
    "    print(\"ğŸ–¼  ì €ì¥:\", out_prev)\n",
    "else:\n",
    "    print(\"âš ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ì—†ìŒ\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60b4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69507a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
