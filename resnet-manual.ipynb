{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd41deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FixB(12시=0°, CCW) → 12시=0°, CW 의 180° 반전(FixB_180) 파이프라인\n",
    "# - raw CSV 보존 → 미리보기(as_is/fixB/fixB_180, 동일 샘플) → fixed CSV 생성 → 학습\n",
    "# - ResNet-18 구조를 직접 레이어 설정하여 통합 (디버깅 용이성)\n",
    "# ============================================================\n",
    "import os, math, csv, glob, random, cv2, numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # ResNet-18 직접 구현을 위해 추가\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "# torchvision.models는 직접 구현한 모델을 사용하므로 주석 처리하거나 제거\n",
    "# import torchvision.models as tvm \n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------\n",
    "# 📌 ResNet-18 직접 구현 레이어 정의 (직접레이어소스코드 내용)\n",
    "# ------------------------------------\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution for downsampling\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18의 기본 블록 (BasicBlock) 구조입니다.\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # 1. Conv1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 2. Conv2\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        # Downsample 경로\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # 잔차 연결을 위한 입력 값 저장\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Downsample 경로가 있다면 실행 (차원 맞추기)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # 잔차 연결 (Residual Connection)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18 구조입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        # 1. 초기 Convolution, BN, ReLU, MaxPool\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 2. ResNet 스테이지 (layer1 ~ layer4)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0]) \n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # 3. 최종 분류 레이어: num_classes=2 (sin, cos)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # ResNet-18의 최종 출력 채널은 512 * BasicBlock.expansion = 512입니다.\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes) \n",
    "\n",
    "        # Weight Initialization (he_normal과 유사한 Kaiming Initialization)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. 초기 레이어\n",
    "        x = self.conv1(x)\n",
    "        # 📌 디버깅 포인트: conv1 출력 크기 확인\n",
    "        # print(\"After conv1:\", x.shape) \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        # 📌 디버깅 포인트: maxpool 출력 크기 확인\n",
    "        # print(\"After maxpool:\", x.shape) \n",
    "\n",
    "        # 2. 스테이지\n",
    "        x = self.layer1(x)\n",
    "        # print(\"After layer1:\", x.shape)\n",
    "        x = self.layer2(x)\n",
    "        # print(\"After layer2:\", x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(\"After layer3:\", x.shape)\n",
    "        x = self.layer4(x)\n",
    "        # print(\"After layer4:\", x.shape)\n",
    "\n",
    "        # 3. 최종 분류\n",
    "        x = self.avgpool(x)\n",
    "        # print(\"After avgpool:\", x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(\"After flatten:\", x.shape)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18_custom(num_classes=2):\n",
    "    \"\"\"\n",
    "    직접 구현한 ResNet-18 (BasicBlock, [2, 2, 2, 2] 블록 구성)을 생성합니다.\n",
    "    \"\"\"\n",
    "    # ResNet-18은 [2, 2, 2, 2] 블록 구성을 사용합니다.\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# ------------------------------------\n",
    "# 📌 수정할 소스코드\n",
    "# ------------------------------------\n",
    "# (생략된 상위 import, 경로 설정, CSV 정리/변환 함수는 그대로 유지)\n",
    "# ...\n",
    "# -----------------\n",
    "# Dataset / Model\n",
    "# -----------------\n",
    "class DialDataset(Dataset):\n",
    "# (DialDataset 클래스 내용은 그대로 유지)\n",
    "# ...\n",
    "    def __init__(self, csv_path, img_size=224, augment=True):\n",
    "        self.items=[]\n",
    "        with open(csv_path,\"r\",encoding=\"utf-8\") as f:\n",
    "            r=csv.reader(f); next(r)\n",
    "            for fp, th, s, c in r:\n",
    "                if os.path.isfile(fp):\n",
    "                    self.items.append((fp,float(th),float(s),float(c)))\n",
    "        if not self.items:\n",
    "            raise RuntimeError(f\"유효 항목 0: {csv_path}\")\n",
    "        augs=[]\n",
    "        if augment: augs += [T.ColorJitter(brightness=0.2, contrast=0.2)]\n",
    "        self.tfm=T.Compose(augs+[\n",
    "            T.Resize((img_size,img_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Lambda(lambda x: x.expand(3,-1,-1)),\n",
    "            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "        ])\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self,i):\n",
    "        fp, th, s, c=self.items[i]\n",
    "        # x=self.tfm(Image.open(fp).convert(\"L\"))\n",
    "        # 그레이스케일로 로드 후 3채널로 확장하는 로직이 T.Lambda에 있음\n",
    "        x=self.tfm(Image.open(fp).convert(\"L\"))\n",
    "        y=torch.tensor([s,c],dtype=torch.float32)\n",
    "        return x,y\n",
    "\n",
    "\n",
    "class AngleHead(nn.Module): \n",
    "    \"\"\"\n",
    "    직접 구현한 ResNet-18을 Backbone으로 사용하도록 수정\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2): # num_classes 인자 추가 (기존 ResNet 클래스에 맞추기 위해)\n",
    "        super().__init__()\n",
    "        # 📌 수정 사항: torchvision.models.resnet18 대신 직접 구현한 resnet18_custom 사용\n",
    "        self.backbone = resnet18_custom(num_classes=num_classes) \n",
    "        \n",
    "        # Note: resnet18_custom 내부에서 이미 self.fc = nn.Linear(512, num_classes)로 \n",
    "        # 최종 레이어가 설정되었으므로, 별도로 fc 레이어를 교체할 필요가 없습니다.\n",
    "        # 기존: self.backbone = tvm.resnet18(weights=None)\n",
    "        # 기존: self.backbone.fc = nn.Linear(self.backbone.fc.in_features, 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=self.backbone(x)\n",
    "        # 📌 중요: 기존 코드의 출력 정규화 로직 유지\n",
    "        return y/(y.norm(dim=1,keepdim=True)+1e-8)\n",
    "\n",
    "def angle_mae_deg(p,t):\n",
    "    dot=(p*t).sum(dim=1).clamp(-1,1)\n",
    "    ang=torch.acos(dot)*180.0/math.pi\n",
    "    return ang.mean().item()\n",
    "\n",
    "# -----------------\n",
    "# 학습 (FIXED CSV 사용) - MSE 추적 추가\n",
    "# -----------------\n",
    "def train_r18(csv_tr=CSV_TRAIN_FIXED, csv_va=CSV_TEST_FIXED,\n",
    "              img_size=224, epochs=30, batch=32, lr=3e-4):\n",
    "    global timestamp\n",
    "    # ... (생략된 학습 코드 내용은 그대로 유지)\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ds_tr=DialDataset(csv_tr, img_size, augment=True)\n",
    "    try:\n",
    "        ds_va=DialDataset(csv_va, img_size, augment=False)\n",
    "    except:\n",
    "        print(\"⚠️ val CSV 없음 → train 15%를 val로 사용\")\n",
    "        n=len(ds_tr); k=max(1,int(n*0.15))\n",
    "        ds_va=torch.utils.data.Subset(ds_tr, list(range(k)))\n",
    "        ds_tr=torch.utils.data.Subset(ds_tr, list(range(k,n)))\n",
    "\n",
    "    dl_tr=DataLoader(ds_tr, batch_size=batch, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dl_va=DataLoader(ds_va, batch_size=batch, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    LOG_DIR = os.path.join(ROOT, \"runs\", f\"r18_fixb180_{timestamp}\")\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "    print(f\"📊 TensorBoard 로그 디렉토리: {LOG_DIR}\")\n",
    "\n",
    "    # 📌 AngleHead 생성 시 num_classes=2 명시 (기본값)\n",
    "    model=AngleHead(num_classes=2).to(device) \n",
    "    \n",
    "    # 📌 디버깅 포인트: 모델 구조 확인 (직접 구현한 ResNet 레이어 확인)\n",
    "    print(\"\\n--- Custom ResNet-18 (AngleHead) Model Structure ---\")\n",
    "    print(model)\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "    \n",
    "    # 📌 디버깅 포인트: 더미 입력으로 한 번 통과시켜 각 레이어 크기 확인\n",
    "    try:\n",
    "        dummy_input = torch.randn(batch, 3, img_size, img_size).to(device)\n",
    "        dummy_output = model(dummy_input)\n",
    "        print(f\"✅ 모델 테스트 통과: 입력 {dummy_input.shape} → 출력 {dummy_output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 테스트 실패: {e}\")\n",
    "        # 여기에 BasicBlock이나 ResNet.forward() 내부에 print(x.shape)를 넣어 디버깅 가능\n",
    "\n",
    "    opt=torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    # # 기존: cos=nn.CosineEmbeddingLoss(); mse=nn.MSELoss()\n",
    "    # # 수정: (reduction='mean'으로 명시)\n",
    "    cos=nn.CosineEmbeddingLoss(reduction='mean')\n",
    "    mse=nn.MSELoss(reduction='mean')\n",
    "    sch=torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "    best=1e9\n",
    "    best_ckpt_path = \"\"\n",
    "\n",
    "    for ep in range(1,epochs+1):\n",
    "        # ... (이후 학습 및 검증 루프 코드는 그대로 유지)\n",
    "        # ========== Training ==========\n",
    "        model.train()\n",
    "        tr_total = 0.0\n",
    "        tr_cos_sum = 0.0\n",
    "        tr_mse_sum = 0.0\n",
    "        \n",
    "        for x,y in dl_tr:\n",
    "            x,y=x.to(device), y.to(device)\n",
    "            p=model(x)\n",
    "            tgt=torch.ones(p.size(0), device=device)\n",
    "            \n",
    "            loss_cos = cos(p,y,tgt)\n",
    "            loss_mse = mse(p,y)\n",
    "            loss = loss_cos + 0.1*loss_mse\n",
    "            \n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            \n",
    "            tr_total += loss.item()*x.size(0)\n",
    "            tr_cos_sum += loss_cos.item()*x.size(0)\n",
    "            tr_mse_sum += loss_mse.item()*x.size(0)\n",
    "        \n",
    "        tr_total /= len(dl_tr.dataset)\n",
    "        tr_cos = tr_cos_sum / len(dl_tr.dataset)\n",
    "        tr_mse = tr_mse_sum / len(dl_tr.dataset)\n",
    "        sch.step()\n",
    "\n",
    "        # ========== Validation ==========\n",
    "        model.eval()\n",
    "        va_total = 0.0\n",
    "        va_cos_sum = 0.0\n",
    "        va_mse_sum = 0.0\n",
    "        mae = 0.0\n",
    "        n = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x,y in dl_va:\n",
    "                x,y=x.to(device), y.to(device)\n",
    "                p=model(x)\n",
    "                tgt=torch.ones(p.size(0), device=device)\n",
    "                \n",
    "                loss_cos = cos(p,y,tgt)\n",
    "                loss_mse = mse(p,y)\n",
    "                loss = loss_cos + 0.1*loss_mse\n",
    "                \n",
    "                va_total += loss.item()*x.size(0)\n",
    "                va_cos_sum += loss_cos.item()*x.size(0)\n",
    "                va_mse_sum += loss_mse.item()*x.size(0)\n",
    "                mae += angle_mae_deg(p,y)*x.size(0)\n",
    "                n += x.size(0)\n",
    "        \n",
    "        va_total /= max(1,n)\n",
    "        va_cos = va_cos_sum / max(1,n)\n",
    "        va_mse = va_mse_sum / max(1,n)\n",
    "        mae /= max(1,n)\n",
    "        \n",
    "        # ========== Console Output ==========\n",
    "        print(f\"[{ep:02d}] train {tr_total:.4f} (cos:{tr_cos:.4f}, mse:{tr_mse:.4f}) | \"\n",
    "              f\"val {va_total:.4f} (cos:{va_cos:.4f}, mse:{va_mse:.4f}) | val-MAE {mae:.2f}°\")\n",
    "\n",
    "        # ========== TensorBoard Logging ==========\n",
    "        writer.add_scalar('Loss/Train_Total', tr_total, ep)\n",
    "        writer.add_scalar('Loss/Train_Cosine', tr_cos, ep)\n",
    "        writer.add_scalar('Loss/Train_MSE', tr_mse, ep)\n",
    "        \n",
    "        writer.add_scalar('Loss/Validation_Total', va_total, ep)\n",
    "        writer.add_scalar('Loss/Validation_Cosine', va_cos, ep)\n",
    "        writer.add_scalar('Loss/Validation_MSE', va_mse, ep)\n",
    "        \n",
    "        writer.add_scalar('Metrics/Validation_MAE_Deg', mae, ep)\n",
    "        writer.add_scalar('Learning_Rate', opt.param_groups[0]['lr'], ep)\n",
    "\n",
    "        timestamp_save = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if mae<best:\n",
    "            best = mae\n",
    "            actual_filename = f\"notimganet_best-{timestamp_save}-mae{mae:.2f}.pth\"\n",
    "            save_path = os.path.join(CKPT_DIR, actual_filename)\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_ckpt_path = save_path\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"✅ best val-MAE = {best:.2f}°  → {best_ckpt_path}\")\n",
    "    return best_ckpt_path\n",
    "\n",
    "best_path = train_r18(epochs=30, batch=32, lr=3e-4)\n",
    "print(\"BEST:\", best_path)\n",
    "\n",
    "# -----------------\n",
    "# 추론 예시(오버레이) – FIXED 기준\n",
    "# -----------------\n",
    "# (이후 추론 코드는 AngleHead 클래스가 수정되었으므로 그대로 사용 가능)\n",
    "# ...\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# 추론 예시(오버레이) – FIXED 기준\n",
    "# -----------------\n",
    "def load_for_infer(ckpt):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=AngleHead().to(device)\n",
    "    sd=torch.load(ckpt, map_location=device)\n",
    "    model.load_state_dict(sd, strict=True); model.eval()\n",
    "    tfm=T.Compose([\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(lambda x: x.expand(3,-1,-1)),\n",
    "        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    return model, tfm, device\n",
    "\n",
    "def infer_one(model, tfm, device, img_path, theta_zero_rad=0.0, ticks_per_rev=100, mm_per_rev=1.0):\n",
    "    x=tfm(Image.open(img_path).convert(\"L\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        y=model(x)[0].cpu().numpy()\n",
    "    sinp,cosp=float(y[0]), float(y[1])\n",
    "    theta=(math.atan2(sinp,cosp))%(2*math.pi)\n",
    "    delta=(theta-theta_zero_rad)%(2*math.pi)\n",
    "    ticks=delta/(2*math.pi)*ticks_per_rev\n",
    "    mm   =delta/(2*math.pi)*mm_per_rev\n",
    "    return theta, ticks, mm\n",
    "\n",
    "def save_overlay(img_path, theta_deg, value_mm, out_path):\n",
    "    g=cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h,w=g.shape[:2]; cx,cy=w//2,h//2; R=int(min(h,w)*0.45)\n",
    "    th=math.radians(theta_deg)\n",
    "    x2=int(round(cx+math.cos(th-math.pi/2)*R))\n",
    "    y2=int(round(cy+math.sin(th-math.pi/2)*R))\n",
    "    vis=cv2.cvtColor(g,cv2.COLOR_GRAY2BGR)\n",
    "    cv2.arrowedLine(vis,(cx,cy),(x2,y2),(0,255,0),2,cv2.LINE_AA,tipLength=0.06)\n",
    "    cv2.putText(vis,f\"{value_mm:.3f} mm\",(10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imwrite(out_path,vis)\n",
    "\n",
    "pngs=glob.glob(os.path.join(TEST_DIR,\"*.png\")) or glob.glob(os.path.join(TRAIN_DIR,\"*.png\"))\n",
    "if pngs:\n",
    "    model,tfm,device=load_for_infer(best_path)\n",
    "    sample=pngs[0]\n",
    "    theta_zero_deg=0.0\n",
    "    theta,ticks,mm=infer_one(model,tfm,device,sample,\n",
    "                              theta_zero_rad=math.radians(theta_zero_deg),\n",
    "                              ticks_per_rev=100, mm_per_rev=1.0)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_prev=os.path.join(DATASET_DIR,f\"_infer_notimganet_preview({timestamp}).jpg\")\n",
    "    save_overlay(sample, theta*180/math.pi, mm, out_prev)\n",
    "    print(f\"🔎 예측: θ={theta*180/math.pi:.2f}°, value={mm:.3f} mm\")\n",
    "    print(\"🖼  저장:\", out_prev)\n",
    "else:\n",
    "    print(\"⚠️ 샘플 이미지 없음\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60b4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69507a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
