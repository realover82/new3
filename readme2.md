논문 검증 결과 정리 (실제 데이터 반영)
1. 핵심 주장 및 검증 지표
섹션	내용
핵심 주장	θ 모델의 특징 재사용은 성능을 향상시키는 것이 아니라, θ 모델의 잠재적인 오류를 ψ 모델에 전파시켜 **결과 예측의 불안정성(Uncertainty)**을 높인다. 따라서 ψ 모델은 θ 모델과 독립적으로, 순수한 ψ 라벨에 집중하여 처음부터 특징을 학습하는 것이 더 예측 안정성이 높다.
검증 지표	평균 MAE, MAE 표준편차 (성능의 일관성), 최악 MAE (치명적인 위험성)

Sheets로 내보내기
2. 결과 섹션 (Result)
두 가지 학습 방식의 통계 결과를 표로 제시합니다.

방법론	평균 MAE (Deg)	MAE 표준편차 (Deg)	최악 MAE (Deg)
A. θ 모델 재사용	11.47 
∘
 	±10.54 
∘
  (높음)	37.48 
∘
 
B. ImageNet 초기화 (재사용 안 함)	10.32 
∘
 	±9.31 
∘
  (낮음)	37.22 
∘
 

Sheets로 내보내기
[결과 서술 예시]

"표 X는 의사 라벨 ψ 학습을 위한 두 가지 전이 학습 전략의 통계적 결과를 보여준다. θ 모델 가중치를 재사용하는 방법론 A는 평균 MAE가 $11.47^{\circ}$로 ImageNet 가중치로 새로 학습한 방법론 B의 $10.32^{\circ}$보다 높았다.

가장 결정적으로, 방법론 A의 성능은 표준편차 $\pm 10.54^{\circ}$로 높은 변동성을 보인 반면, 방법론 B는 $\pm 9.31^{\circ}$로 더 낮은 변동성과 더 높은 예측 안정성을 입증했다. 두 방법론 모두 최악 MAE가 $37^{\circ}$대로 유사한 치명적 오류 위험을 보였으나, 평균적인 성능과 안정성에서 방법론 B가 뚜렷하게 우위를 점했다."

3. 논의 섹션 (Discussion)
[논의 작성 예시]

"실험 결과에 따르면, θ 모델 가중치를 재사용하는 방법론 A는 전반적인 성능과 안정성 모두에서 ImageNet 초기화 방식(방법론 B)보다 열등한 것으로 검증되었다.

방법론 A의 높은 표준편차(±10.54 
∘
 )는 θ 예측에 최적화된 특징이 ψ 라벨의 상대적 오차 예측에는 부적합할 경우, 해당 특징이 오히려 θ 모델의 잠재적 오차를 ψ 학습 과정에 그대로 전파(Error Propagation)시키는 현상을 유발함을 시사한다. 이로 인해 모델의 성능이 데이터셋별로 극단적으로 요동치는 **불안정성(Inconsistency)**을 보였다.

따라서 본 연구는 ψ 라벨을 사용하는 후속 모델 학습 시에는 기존 θ 모델의 특징을 재사용하는 것을 지양하고, ImageNet 가중치 기반으로 독립적인 학습을 시작하여 ψ 값에 최적화된 특징을 새로 학습하는 것이 신뢰할 수 있고 우수한 결과를 보장하는 방법임을 최종적으로 검증하였다."